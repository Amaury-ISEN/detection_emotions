{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'affichage des émoticônes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_emote(statut):\n",
    "    \n",
    "    if statut == \"Angry\":\n",
    "        img2 = angry\n",
    "        \n",
    "    elif statut == \"Neutral\":\n",
    "        img2 = neutral\n",
    "        \n",
    "    elif statut == \"Sad\":\n",
    "        img2 = sad\n",
    "        \n",
    "    elif statut == \"Happy\":\n",
    "        img2 = happy\n",
    "        \n",
    "    elif statut == \"Disgust\":\n",
    "        img2 = disgust\n",
    "        \n",
    "    elif statut == \"Fear\":\n",
    "        img2 = fear\n",
    "        \n",
    "    elif statut == \"Surprise\":\n",
    "        img2 = surprise\n",
    "    \n",
    "    else : img2 = rien\n",
    "        \n",
    "    # Création d'une région d'intérêt openCV au coin supérieur-gauche & de la taille du smiley :\n",
    "    rows,cols,channels = img2.shape\n",
    "    roi = im2[0:rows, 0:cols ]\n",
    "\n",
    "    # Création d'un masque du smiley (et son masque inverse)\n",
    "    img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 30, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Black-out du smiley dans la ROI :\n",
    "    im_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "    \n",
    "    # De l'image du smiley, on ne prend que le smiley en lui-même :\n",
    "    img2_fg = cv2.bitwise_and(img2,img2,mask = mask)\n",
    "\n",
    "    # Ajout du smiley dans le ROI et modification de l'image principale pour intégrer l'ajout :\n",
    "    dst = cv2.add(im_bg,img2_fg)\n",
    "    im2[0:rows, 0:cols ] = dst\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programme de détection d'émotions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./modele_emotions/\")\n",
    "sad = cv2.imread('./sad.png')\n",
    "happy = cv2.imread('./happy.png')\n",
    "rien = cv2.imread('./rien.png')\n",
    "angry = cv2.imread('./angry.png')\n",
    "disgust = cv2.imread('./disgust.png')\n",
    "surprise = cv2.imread('./surprise.png')\n",
    "neutral = cv2.imread('./neutral.png')\n",
    "fear = cv2.imread('./fear.png')\n",
    "\n",
    "# Facteur pour le redimensionnement de l'image\n",
    "imgsize = 4\n",
    "# Allumage de la webcam : \n",
    "camera = cv2.VideoCapture(0)\n",
    "# Identification d'un visage :\n",
    "classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Touche pour fermer, initialisée à 0, si elle passe à 27 avec le waitKey(), c'est que l'utilisateur a fait ESC\n",
    "key=0\n",
    "while key!=27:\n",
    "    # Deux variables vont être continuellement remplies via la cam avec la méthode read().\n",
    "    # rval est un booléen qui atteste du fait que les frames de la cam sont bien lues, im sera notre image vidéo.\n",
    "    (rval, im) = camera.read()\n",
    "    # On passe l'image en miroir\n",
    "    im=cv2.flip(im,1,1)\n",
    "    \n",
    "    # Création d'une copie de l'image issue de la webcam\n",
    "    # La prédiction se fera via im sans le smiley pour éviter qu'il soit reconnu comme un visage:\n",
    "    im2 = im.copy()\n",
    "    \n",
    "    # Redimensionnement à la baisse de l'image récupérée de la webcam (640*480 => 160*120)\n",
    "    # Objectif : soulaver le classifieur de haar.\n",
    "    image_redim = cv2.resize(im, (im.shape[1] // imgsize,\n",
    "                             im.shape[0] // imgsize))\n",
    "        \n",
    "    # On crée nos frames de visage reconnu par classifieur haar appliqué aux images issues des frames redimensionnées :\n",
    "    face_rec = classifier.detectMultiScale(image_redim) \n",
    "    # print(\"face_rec=\",face_rec)\n",
    "    \n",
    "    # Si le type de face_rec n'est pas tuple, cela veut dire que face_rec != () (càd qu'il n'est pas vide)\n",
    "    if type(face_rec) != tuple: # faut-il aussi faire \"and 0 not in face_rec[0]\" ?\n",
    "        # Pour chaque visage reconnu :\n",
    "        for i in face_rec:\n",
    "            # Le classifieur haar travaillait sur images réduites de facteur 4 mais pour découper\n",
    "            # un médaillon rectangulaire qui correspond au visage détecté sur notre image webcam,\n",
    "            # il faut à nouveau multiplier les données d'output du classifieur par le imsize :\n",
    "            (x, y, l, w) = [v * imgsize for v in i]\n",
    "            # On découpe dans l'image de la caméra avec les coordonnées obtenues grâce à haar.\n",
    "            face_img = im[y:(y+w), x:(x+l)]\n",
    "            # On redimensionne :\n",
    "            face_redim=cv2.resize(face_img,(100,100))\n",
    "            # On passe en gris :\n",
    "            face_gray = cv2.cvtColor(face_redim, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            # En l'absence d'un modèle entraîné sur un dataset dûment data augmenté\n",
    "            # avec des doublons d'images aux contrastes et luminosités variées, le\n",
    "            # réglage de contraste et de brightness pour la prédiction est crucial.\n",
    "            # Selon l'éclairage dans lequel tourne l'appli et la webcam, il faut régler\n",
    "            # les deux paramètres suivants.\n",
    "            # S'il fait sombre, brightness à 2 marche bien, sinon 1.\n",
    "            \n",
    "            contrast = 2\n",
    "            brightness = 1\n",
    "            face_contrast = cv2.addWeighted(face_gray, contrast, face_gray, 0, brightness)\n",
    "\n",
    "            # On standardise la valeur des pixels de l'array :\n",
    "            face_standardise= face_contrast.astype('float')/255\n",
    "\n",
    "            # On reshape pour fonctionner avec le CNN :\n",
    "            #face_reshaped = face_standardise.reshape(-1,48,48,1)\n",
    "            \n",
    "            face_resized = cv2.resize(face_standardise, dsize=(48,48))\n",
    "            face_reshaped = face_resized.reshape(-1,48,48,1)\n",
    "            \n",
    "            afficher_emote(statut=\"rien\")\n",
    "            prediction = model.predict(face_reshaped)\n",
    "            #cv2.putText(im2, str(prediction[0].round(2)), (0, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "\n",
    "            # La prédiction sur image issue de flux vidéo fonctionne mais il faut\n",
    "            # définir un seuil car on atteint pas des taux de certitude de 99%.\n",
    "            if prediction[0].argmax() == 0 :\n",
    "                #cv2.putText(im2, \"Angry\", (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "                afficher_emote(statut=\"Angry\")\n",
    "                cv2.putText(im2, \"Reste calme et pose ce flingue !\", (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "\n",
    "            \n",
    "            elif prediction[0].argmax() == 1 :\n",
    "                #cv2.putText(im2, \"Disgust\", (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "                afficher_emote(statut=\"Disgust\")\n",
    "                cv2.putText(im2, \"Incroyable, tu as débloqué celle-ci ?!\", (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "\n",
    "\n",
    "            elif prediction[0].argmax() == 2 :\n",
    "                #cv2.putText(im2, \"Fear\", (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "                afficher_emote(statut=\"Fear\")\n",
    "                cv2.putText(im2, \"Derrière-toi ! La COVID !\", (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "\n",
    "\n",
    "            elif prediction[0].argmax() == 3 :\n",
    "                #cv2.putText(im2, \"Happy\", (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "                afficher_emote(statut=\"Happy\")\n",
    "                cv2.putText(im2, \"Il est content !\", (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "\n",
    "\n",
    "            elif prediction[0].argmax() == 4 :\n",
    "                #cv2.putText(im2, \"Neutral\", (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "                afficher_emote(statut=\"Neutral\")\n",
    "                cv2.putText(im2, \"Neutre, RAS !\", (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "\n",
    "                \n",
    "            elif prediction[0].argmax() == 5 :\n",
    "                #cv2.putText(im2, \"Sad\", (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "                afficher_emote(statut=\"Sad\")\n",
    "                cv2.putText(im2, \"Ne sois pas triste, la vie est belle !\", (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "\n",
    "\n",
    "            elif prediction[0].argmax() == 6 :\n",
    "                #cv2.putText(im2, \"Surprise\", (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "                afficher_emote(statut=\"Surprise\")\n",
    "                cv2.putText(im2, \"Surprise !\", (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))\n",
    "\n",
    "\n",
    "\n",
    "    # On affiche im2 et pas im pour avoir l'image modifiée avec le smiley :\n",
    "    cv2.imshow('Detecteur de masques',im2)\n",
    "    key = cv2.waitKey(10)\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
